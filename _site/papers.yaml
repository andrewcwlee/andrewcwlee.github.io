papers:
  - name: adaramp
    title:
      name: >-
        Automating Infrastructure Surveying: A Framework for Geometric Measurements and Compliance Assessment Using Point Cloud Data
      link: 
    authors:
      - name: Amin Ghafourian
      - me: true
      - name: Dechen Gao
        href: https://gaodechen.github.io/
      - name: Tyler Beer
        href: https://www.linkedin.com/in/tyler-beer/
      - name: Kin Yen
      - name: Iman Soltani
        href: https://faculty.engineering.ucdavis.edu/soltani/
    conference:
      name: Preprint
    links:
      - name: arXiv
        href: https://arxiv.org/abs/2505.05752
    highlighted: false
    nogif: true
    description: This paper presents a framework for automation of geometric measurements and compliance assessment using point cloud data. The proposed approach integrates deep learning-based detection and segmentation, in conjunction with geometric and signal processing techniques, to automate surveying tasks. As a proof of concept, we apply this framework to automatically evaluate the compliance of curb ramps with the Americans with Disabilities Act (ADA), demonstrating the utility of point cloud data in survey automation.
  - name: iradas
    title:
      name: >-
        Infrared Vision Systems for Emergency Vehicle Driver Assistance in Low-Visibility Conditions
      link: 
    authors:
      - name: M-Mahdi Naddaf-Sh
        href: https://naddafs.com
      - me: true
      - name: Kin Yen
      - name: Eemon Amini
      - name: Iman Soltani
        href: https://faculty.engineering.ucdavis.edu/soltani/
    conference:
      name: Preprint
    links:
      - name: arXiv
        href: https://arxiv.org/abs/2504.14078
    highlighted: false
    nogif: false
    description: This study investigates the potential of infrared (IR) camera technology to enhance driver safety for emergency vehicles operating in low-visibility conditions, particularly at night and in dense fog. 
  - name: avaloha
    title:
      name: >-
        Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation
      link: 
    authors:
      - name: Ian Chuang
        href: https://ian-chuang.github.io/
        star: true
      - me: true
        star: true
      - name: Dechen Gao
        href: https://gaodechen.github.io/
      - name: M-Mahdi Naddaf-Sh
        href: https://naddafs.com
      - name: Iman Soltani
        href: https://faculty.engineering.ucdavis.edu/soltani/

    conference:
      name: Workshop on Whole-body Control and Bimanual Manipulation @ CoRL 2024 <br> ICRA 2025
    links:
      - name: arXiv
        href: https://arxiv.org/abs/2409.17435
      - name: website
        href: https://soltanilara.github.io/av-aloha/
      - name: code
        href: https://github.com/soltanilara/av-aloha
      - name: code (VR)
        href: https://github.com/soltanilara/av-aloha-unity
      - name : video
        href: https://www.youtube.com/watch?v=DwJzdaKM4N0
      - name: poster (ICRA 2025)
        href: https://www.youtube.com/watch?v=0g1r7v2aX4E
    highlighted: true
    nogif: false
    description: We introduce AV-ALOHA, a new bimanual teleoperation robot system that extends the ALOHA 2 robot system with Active Vision. This system provides an immersive teleoperation experience, with bimanual first-person control, enabling the operator to dynamically explore and search the scene and simultaneously interact with the environment. We conduct imitation learning experiments and our results show significant improvements over fixed cameras in tasks with limited visibility.



  - name: interact
    title:
      name: >-
        InterACT: Inter-dependency Aware Action Chunking with Hierarchical Attention Transformers for Bimanual Manipulation
      link: 
    authors:
      - me: true
      - name: Ian Chuang
        href: https://ian-chuang.github.io/
      - name: Ling-Yuan Chen
        href: https://www.linkedin.com/in/lingyuanchen/
      - name: Iman Soltani
        href: https://faculty.engineering.ucdavis.edu/soltani/
    conference:
      name: CoRL 2024
    links:
      - name: arXiv
        href: https://www.arxiv.org/abs/2409.07914
      - name: website
        href: https://soltanilara.github.io/interact/
      - name: code
        href: https://github.com/soltanilara/InterACT-LeRobot
      - name: poster (CoRL 2024)
        href: '/files/poster/interact-poster.pdf'
    highlighted: true
    nogif: false
    description: InterACT is an imitation learning model that captures and extracts inter-dependencies between dual-arm joint positions and visual inputs. By doing so, InterACT guides the two arms to perform bimanual tasks with precisionâ€”independently yet in seamless coordination.
