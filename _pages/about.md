---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class="small_font">
  I am a Ph.D. student in Computer Science at the <a href="https://ucdavis.edu/" target="_blank">University of California Davis</a>, where I am part of the <a href="https://soltanilab.engineering.ucdavis.edu" target="_blank">Laboratory for AI, Robotics and Automation (LARA)</a>, under the guidance of Prof. <a href="https://faculty.engineering.ucdavis.edu/soltani/\" target="_blank">Iman Soltani</a>. Before starting my Ph.D., I was a Master‚Äôs student at the same lab, and I received my B.S. in Mechanical Engineering from <a href="https://www.hanyang.ac.kr/web/eng/home" target="_blank">Hanyang University</a> in Seoul, South Korea. <br><br>
  My research focuses on developing robotic systems capable of <b>mimicking "real" human behavior and dexterity</b> in complex and unstructured environments. In that regard, my recent works are aimed at bimanual coordination and human-like perception.
  <br><br>
  <i>I am actively looking for <b>internship opportunities for 2025!</b> Please reach out if your team has any open positions!</i> 
</span>

<div>
<div class="recent_updates">Updates</div>
<ul style="margin-top:-3px; background-color: #fafafa; padding-top: 20px; padding-bottom: 20px" class="updates">
	<li><span class="updates-month">OCT'24</span> <span class="updates-content">"Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation" got accepted at <b>Workshop on Whole-body Control and Bimanual Manipulation at CoRL 2024</b>!</span></li>
	<li><span class="updates-month">OCT'24</span> <span class="updates-content">We released the <a target='_blank' href='https://github.com/soltanilara/av-aloha'>code</a> and <a target='_blank' href='https://github.com/soltanilara/av-aloha-unity'>code (VR)</a> for AV-ALOHA!</span></li>
	<li><span class="updates-month">SEP'24</span> <span class="updates-content">"InterACT: Inter-dependency Aware Action Chunking with Hierarchical Attention Transformers for Bimanual Manipulation" got accepted at <b>CoRL 2024</b>!</span></li>
	<li><span class="updates-month">MAY'24</span> <span class="updates-content">I received the Summer Ph.D. Fellowship from UC Davis Computer Science Graduate Group!</span></li>
</ul>
</div>


<div class="recent_updates" id="publications">Publications</div>
<span style="font-size:14px;margin-left: 25px;display: block;">
Most recent publications on <a style="text-decoration:none!important;" href="https://scholar.google.com/citations?user=cfIJXfoAAAAJ&hl=en" target="_blank">Google Scholar</a>.<br>
<b>‚Ä°</b> indicates equal contribution.</span>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/avaloha-teaser.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation</div>
		<div class="sub-title">Ian Chuang<sup>‚Ä°</sup>, <span class="author-me">Andrew Lee<sup>‚Ä°</sup></span>, Dechen Gao, Iman Soltani<br>
		<i>
		<b>
		Workshop on Whole-body Control and Bimanual Manipulation @ CoRL 2024</b><br>
		preprint 2024</i><br>
			<a target="_blank" href="https://soltanilara.github.io/av-aloha/"><button class="btn pub-btn"><i class="fas fa-globe"></i> project page</button></a>
			<a target="_blank" href="https://arxiv.org/abs/2409.17435"><button class="btn pub-btn"><i class="ai ai-arxiv"></i> arXiv</button></a>
			<a target="_blank" href="https://github.com/soltanilara/av-aloha"><button class="btn pub-btn"><i class="fab fa-github"></i> code</button></a>
			<a target="_blank" href="https://github.com/soltanilara/av-aloha-unity"><button class="btn pub-btn"><i class="fab fa-github"></i> code (VR)</button></a>
			<a target="_blank" href="https://www.youtube.com/watch?v=DwJzdaKM4N0"><button class="btn pub-btn"><i class="fas fa-video"></i> video</button></a>
		</div>
		<span class="research-text">
		<b>tl;dr</b> We introduce AV-ALOHA, a bimanual robot system with 7-DoF active vision that is an extension of ALOHA 2. This system offers an immersive teleoperation experience using VR and serves as a platform to evaluate active vision in imitation learning and manipulation.
		</span>
	</div>
</div>

<div class="research-block">
	<div class="left">
		<span class="research-img">
			<img src="/images/teasers/interact-teaser.gif">
		</span>
	</div>
	<div class="right">
		<div class="title">InterACT: Inter-dependency Aware Action Chunking with Hierarchical Attention Transformers for Bimanual Manipulation</div>
		<div class="sub-title"><span class="author-me">Andrew Lee</span>, Ian Chuang, Ling-Yuan Chen, Iman Soltani<br>
			<i><b>CoRL 2024</b></i><br>
			<a target="_blank" href="https://soltanilara.github.io/interact/"><button class="btn pub-btn"><i class="fas fa-globe"></i> project page</button></a>
			<a target="_blank" href="https://www.arxiv.org/abs/2409.07914"><button class="btn pub-btn"><i class="ai ai-arxiv"></i> arXiv</button></a>
			<button class="btn btn--disabled pub-btn"><i class="fab fa-github"></i> code</button>
			<button class="btn btn--disabled pub-btn"><i class="fas fa-video"></i> spotlight video</button>
			<button class="btn btn--disabled pub-btn"><i class="fas fa-scroll"></i> poster</button>
		</div>
		<span class="research-text">
		<b>tl;dr</b> InterACT builds on the concept of hierarchical attention mechanisms, capturing and extracting the inter-dependencies between dual-arm joint positions and visual inputs. By doing so, InterACT guides the two arms to perform bimanual tasks with precision‚Äîindependently yet in seamless coordination.
		</span>
	</div>
</div>

<div class="recent_updates" id="misc">Experiences</div>

<div class="research-block">
	<div class="left">
		<span class="ex-img">
			<img src="/images/logowhite.png">
		</span>
	</div>
	<div class="right">
		<div class="ex-title">Graduate Student Researcher at <a href="https://soltanilab.engineering.ucdavis.edu" target="_blank">LARA</a></div>
		<div class="sub-title">UC Davis<br><i>2023.05 - Present</i></div>
	</div>
</div>

<div class="recent_updates" id="misc">Misc</div>
<span class="small_font">
	Aside from research, I have a passion for photography, especially <a href="https://en.wikipedia.org/wiki/Street_photography" target="_blank">street photography</a>. It‚Äôs my way of reconnecting with the human side of things in this <b>üå™Ô∏è whirlwind üå™Ô∏è of technology</b>‚Äîcapturing moments that no algorithm could ever predict.
</span>